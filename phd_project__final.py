# -*- coding: utf-8 -*-
"""PhD project_ final.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ntmBb76j9R-yCiFpCwoa-wvKoLJ0Ntya

# Creating the dataset
"""

!pip install scikit-fuzzy

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from skfuzzy import control as ctrl
import skfuzzy as fuzz

# Create a DataFrame with simulated data
np.random.seed(42)
data = {
    'Proposal_ID': range(1, 501),  # 100 proposals
    'Innovation': np.random.uniform(0, 1, 500),
    'Risk': np.random.uniform(0, 1, 500),
    'ROI': np.random.uniform(0, 1, 500),
    'Past_Performance': np.random.uniform(0, 1, 500),
    'Binary_Decision': np.random.choice(['Fund', 'Not Fund'], 500)
}
df = pd.DataFrame(data)

"""# Running SHAP and LIME"""

!pip install shap
!pip install lime

import shap
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier

# Assuming 'df' is your DataFrame and 'target' is your target variable
X = df.drop('Binary_Decision', axis=1)  # Make sure to replace 'target' with your actual target column name
y = df['Binary_Decision']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Training a model
model = DecisionTreeClassifier(random_state=42)
model.fit(X_train, y_train)

# Computing SHAP values
explainer = shap.Explainer(model, X_train)
shap_values = explainer(X_test)

# Visualizing SHAP values for the first prediction
# Note: Adjust the index [0] based on the class you're interested in if it's a multiclass classification
if len(shap_values.shape) == 3:  # Checking if it's a multiclass classification
    # Visualize the first prediction's explanation for the first class
    shap.plots.waterfall(shap_values[0][0])
else:
    # For binary classification
    shap.plots.waterfall(shap_values[0])

import shap
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier

# Assuming 'df' is your DataFrame and 'Binary_Decision' is already in numeric binary format (0 and 1)
X = df.drop('Binary_Decision', axis=1)
y = df['Binary_Decision']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Training a model
model = DecisionTreeClassifier(random_state=42)
model.fit(X_train, y_train)

# Computing SHAP values
explainer = shap.Explainer(model, X_train)
shap_values = explainer(X_test)

# Visualizing SHAP values for the first prediction
# Since your classification is binary, directly visualize the SHAP summary plot
shap.summary_plot(shap_values, X_test, feature_names=X_test.columns)

# Count the number of NaNs in the 'Binary_Decision' column
nan_count_binary_decision = df['Binary_Decision'].isna().sum()

# To see the count of NaNs across the entire DataFrame
nan_count_total = df.isna().sum()

print(f"Number of NaNs in 'Binary_Decision': {nan_count_binary_decision}")
print("Number of NaNs in each column:")
print(nan_count_total)

import shap
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier

# Assuming 'df' is your DataFrame and 'Binary_Decision' is already in numeric binary format (0 and 1)
X = df.drop('Binary_Decision', axis=1)
y = df['Binary_Decision']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Training a model
model = DecisionTreeClassifier(random_state=42)
model.fit(X_train, y_train)

# Computing SHAP values
explainer = shap.Explainer(model, X_train)
shap_values = explainer(X_test)

# Visualizing SHAP values for the first prediction
# Since your classification is binary, directly visualize the SHAP summary plot
shap.summary_plot(shap_values, X_test, feature_names=X_test.columns)

df.head()

# Convert 'Fund' to 1 and 'Not Fund' to 0
df['Binary_Decision'] = df['Binary_Decision'].map({'Fund': 1, 'Not Fund': 0})

# Setup the Fuzzy Logic System
# Antecedents (Inputs)
innovation = ctrl.Antecedent(np.arange(0, 1.1, 0.1), 'Innovation')
risk = ctrl.Antecedent(np.arange(0, 1.1, 0.1), 'Risk')
roi = ctrl.Antecedent(np.arange(0, 1.1, 0.1), 'ROI')
past_performance = ctrl.Antecedent(np.arange(0, 1.1, 0.1), 'Past_Performance')

# Membership functions
innovation.automf(3)
risk.automf(3)
roi.automf(3)
past_performance.automf(3)

# Consequent (Output)
funding_score = ctrl.Consequent(np.arange(0, 1.1, 0.1), 'Funding_Score')
funding_score['low'] = fuzz.trimf(funding_score.universe, [0, 0.3, 0.6])
funding_score['medium'] = fuzz.trimf(funding_score.universe, [0.4, 0.7, 1.0])
funding_score['high'] = fuzz.trimf(funding_score.universe, [0.7, 1.0, 1.0])

# Fuzzy Rules
rule1 = ctrl.Rule(innovation['poor'] | risk['good'], funding_score['low'])
rule2 = ctrl.Rule(roi['average'] | past_performance['average'], funding_score['medium'])
rule3 = ctrl.Rule(innovation['good'] & risk['poor'], funding_score['high'])

# Control System
funding_ctrl = ctrl.ControlSystem([rule1, rule2, rule3])
funding = ctrl.ControlSystemSimulation(funding_ctrl)

# Calculate Fuzzy Scores for Each Proposal
fuzzy_scores = []
for i in range(len(df)):
    funding.input['Innovation'] = df.loc[i, 'Innovation']
    funding.input['Risk'] = df.loc[i, 'Risk']
    funding.input['ROI'] = df.loc[i, 'ROI']
    funding.input['Past_Performance'] = df.loc[i, 'Past_Performance']
    funding.compute()
    fuzzy_scores.append(funding.output['Funding_Score'])
df['Fuzzy_Score'] = fuzzy_scores

# Visualize Membership Functions for Innovation
innovation.view()

# Visualize Fuzzy Score Distribution
plt.figure(figsize=(10, 6))
plt.hist(df['Fuzzy_Score'], bins=20, color='skyblue', edgecolor='black')
plt.title('Distribution of Fuzzy Scores')
plt.xlabel('Fuzzy Score')
plt.ylabel('Frequency')
plt.show()

# Add the code for nuanced categorization based on Fuzzy Scores here
# Conditions and choices for nuanced categorization
conditions = [
    df['Fuzzy_Score'] >= 0.7,  # Strongly recommend funding
    (df['Fuzzy_Score'] < 0.7) & (df['Fuzzy_Score'] >= 0.4),  # Recommend funding
    df['Fuzzy_Score'] < 0.4  # Consider for funding
]
choices = ['Strongly Recommend Funding', 'Recommend Funding', 'Consider for Funding']
df['Nuanced_Decision'] = np.select(conditions, choices, default='Review Further')

# Display the first few rows of the modified DataFrame
print(df.head())

df.head()

# For simplicity, let's replace NaNs with a placeholder like -1 (or choose a method that suits your needs)
df['Binary_Decision'].fillna(-1, inplace=True)

# Proceed with your data splitting and model training as you did before

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from skfuzzy import control as ctrl
import skfuzzy as fuzz

# Create a DataFrame with simulated data
np.random.seed(42)
data = {
    'Proposal_ID': range(1, 101),  # 100 proposals
    'Innovation': np.random.uniform(0, 1, 100),
    'Risk': np.random.uniform(0, 1, 100),
    'ROI': np.random.uniform(0, 1, 100),
    'Past_Performance': np.random.uniform(0, 1, 100),
    'Binary_Decision': np.random.choice(['Fund', 'Not Fund'], 100)
}
df = pd.DataFrame(data)

# Setup the Fuzzy Logic System
# Antecedents (Inputs)
innovation = ctrl.Antecedent(np.arange(0, 1.1, 0.1), 'Innovation')
risk = ctrl.Antecedent(np.arange(0, 1.1, 0.1), 'Risk')
roi = ctrl.Antecedent(np.arange(0, 1.1, 0.1), 'ROI')
past_performance = ctrl.Antecedent(np.arange(0, 1.1, 0.1), 'Past_Performance')

# Membership functions
innovation.automf(3)
risk.automf(3)
roi.automf(3)
past_performance.automf(3)

# Consequent (Output)
funding_score = ctrl.Consequent(np.arange(0, 1.1, 0.1), 'Funding_Score')
funding_score['low'] = fuzz.trimf(funding_score.universe, [0, 0.3, 0.6])
funding_score['medium'] = fuzz.trimf(funding_score.universe, [0.4, 0.7, 1.0])
funding_score['high'] = fuzz.trimf(funding_score.universe, [0.7, 1.0, 1.0])

# Fuzzy Rules
rule1 = ctrl.Rule(innovation['poor'] | risk['good'], funding_score['low'])
rule2 = ctrl.Rule(roi['average'] | past_performance['average'], funding_score['medium'])
rule3 = ctrl.Rule(innovation['good'] & risk['poor'], funding_score['high'])

# Control System
funding_ctrl = ctrl.ControlSystem([rule1, rule2, rule3])
funding = ctrl.ControlSystemSimulation(funding_ctrl)

# Calculate Fuzzy Scores for Each Proposal
fuzzy_scores = []
for i in range(len(df)):
    funding.input['Innovation'] = df.loc[i, 'Innovation']
    funding.input['Risk'] = df.loc[i, 'Risk']
    funding.input['ROI'] = df.loc[i, 'ROI']
    funding.input['Past_Performance'] = df.loc[i, 'Past_Performance']
    funding.compute()
    fuzzy_scores.append(funding.output['Funding_Score'])
df['Fuzzy_Score'] = fuzzy_scores

# Visualize Membership Functions for Innovation
innovation.view()

# Visualize Fuzzy Score Distribution
plt.figure(figsize=(10, 6))
plt.hist(df['Fuzzy_Score'], bins=20, color='skyblue', edgecolor='black')
plt.title('Distribution of Fuzzy Scores')
plt.xlabel('Fuzzy Score')
plt.ylabel('Frequency')
plt.show()

# Add the code for nuanced categorization based on Fuzzy Scores here
# Conditions and choices for nuanced categorization
conditions = [
    df['Fuzzy_Score'] >= 0.7,  # Strongly recommend funding
    (df['Fuzzy_Score'] < 0.7) & (df['Fuzzy_Score'] >= 0.5),  # Recommend funding
    (df['Fuzzy_Score'] < 0.5) & (df['Fuzzy_Score'] >= 0.4),  # Consider for funding
    df['Fuzzy_Score'] < 0.4   # Do not fund
]
choices = ['Strongly Recommend Funding', 'Recommend Funding', 'Consider for Funding', 'Do Not Fund']

df['Nuanced_Decision'] = np.select(conditions, choices, default='Review Further')


# Display the first few rows of the modified DataFrame
print(df.head())

df.shape

df.head(30)

# Assuming 'Binary_Decision' is the column with original 'Fund' or 'Not Fund' decisions
# and 'Nuanced_Decision' is the column with the nuanced decisions
comparison_table = pd.crosstab(df['Binary_Decision'], df['Nuanced_Decision'])

# This will print out the comparison table
print(comparison_table)

# Assuming 'df' is your DataFrame with both 'Binary_Decision' and 'Nuanced_Decision' columns
# and that the 'Binary_Decision' column has been converted to a binary format with 'Fund' as 1 and 'Not Fund' as 0

# Mapping the binary decisions to more descriptive terms for comparison
df['Binary_Decision_Mapped'] = df['Binary_Decision'].map({1: 'Fund', 0: 'Not Fund'})

# Now, create a cross-tabulation
comparison_table = pd.crosstab(df['Binary_Decision_Mapped'], df['Nuanced_Decision'])

# Let's print the comparison table
print(comparison_table)

df.head()

# prompt: search row , where Nuanced_Decision column value = Do Not Fund

df_filtered = df[df['Nuanced_Decision'] == 'Do Not Fund']
print(df_filtered.head())

# prompt: how many rows df['Fuzzy_Score'] < 0.3

df[df['Fuzzy_Score'] < 0.4].shape[0]

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from skfuzzy import control as ctrl
import skfuzzy as fuzz
from sklearn.svm import SVC
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

# Create a DataFrame with simulated data
np.random.seed(42)
data = {
    'Proposal_ID': range(1, 101),  # 100 proposals
    'Innovation': np.random.uniform(0, 1, 100),
    'Risk': np.random.uniform(0, 1, 100),
    'ROI': np.random.uniform(0, 1, 100),
    'Past_Performance': np.random.uniform(0, 1, 100),
    'Binary_Decision': np.random.choice(['Fund', 'Not Fund'], 100)
}
df = pd.DataFrame(data)

# Convert Binary_Decision to numerical values for SVM
df['Binary_Decision'] = df['Binary_Decision'].map({'Fund': 1, 'Not Fund': 0})

# Setup the Fuzzy Logic System
# Antecedents (Inputs)
innovation = ctrl.Antecedent(np.arange(0, 1.1, 0.1), 'Innovation')
risk = ctrl.Antecedent(np.arange(0, 1.1, 0.1), 'Risk')
roi = ctrl.Antecedent(np.arange(0, 1.1, 0.1), 'ROI')
past_performance = ctrl.Antecedent(np.arange(0, 1.1, 0.1), 'Past_Performance')

# Membership functions
innovation.automf(3)
risk.automf(3)
roi.automf(3)
past_performance.automf(3)

# Consequent (Output)
funding_score = ctrl.Consequent(np.arange(0, 1.1, 0.1), 'Funding_Score')
funding_score['low'] = fuzz.trimf(funding_score.universe, [0, 0.3, 0.6])
funding_score['medium'] = fuzz.trimf(funding_score.universe, [0.4, 0.7, 1.0])
funding_score['high'] = fuzz.trimf(funding_score.universe, [0.7, 1.0, 1.0])

# Fuzzy Rules
rule1 = ctrl.Rule(innovation['poor'] | risk['good'], funding_score['low'])
rule2 = ctrl.Rule(roi['average'] | past_performance['average'], funding_score['medium'])
rule3 = ctrl.Rule(innovation['good'] & risk['poor'], funding_score['high'])

# Control System
funding_ctrl = ctrl.ControlSystem([rule1, rule2, rule3])
funding = ctrl.ControlSystemSimulation(funding_ctrl)

# Calculate Fuzzy Scores for Each Proposal
fuzzy_scores = []
for i in range(len(df)):
    funding.input['Innovation'] = df.loc[i, 'Innovation']
    funding.input['Risk'] = df.loc[i, 'Risk']
    funding.input['ROI'] = df.loc[i, 'ROI']
    funding.input['Past_Performance'] = df.loc[i, 'Past_Performance']
    funding.compute()
    fuzzy_scores.append(funding.output['Funding_Score'])
df['Fuzzy_Score'] = fuzzy_scores

# Visualize Membership Functions for Innovation
innovation.view()

# Visualize Fuzzy Score Distribution
plt.figure(figsize=(10, 6))
plt.hist(df['Fuzzy_Score'], bins=20, color='skyblue', edgecolor='black')
plt.title('Distribution of Fuzzy Scores')
plt.xlabel('Fuzzy Score')
plt.ylabel('Frequency')
plt.show()

# Conditions and choices for nuanced categorization
conditions = [
    df['Fuzzy_Score'] >= 0.7,  # Strongly recommend funding
    (df['Fuzzy_Score'] < 0.7) & (df['Fuzzy_Score'] >= 0.5),  # Recommend funding
    (df['Fuzzy_Score'] < 0.5) & (df['Fuzzy_Score'] >= 0.3),  # Consider for funding
    df['Fuzzy_Score'] < 0.3  # Do not fund
]
choices = ['Strongly Recommend Funding', 'Recommend Funding', 'Consider for Funding', 'Do Not Fund']
df['Nuanced_Decision'] = np.select(conditions, choices, default='Review Further')

# Use the Fuzzy Scores as input features for SVM
X = df[['Innovation', 'Risk', 'ROI', 'Past_Performance', 'Fuzzy_Score']]
y = df['Binary_Decision']

# Split data into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize and train the SVM model
svm_model = SVC(probability=True, random_state=42)
svm_model.fit(X_train, y_train)

# Predict using the SVM model
svm_predictions = svm_model.predict(X_test)

# Measure the accuracy of the SVM
svm_accuracy = accuracy_score(y_test, svm_predictions)
print(f"SVM model accuracy: {svm_accuracy:.2f}")

# Add SVM predictions to the DataFrame
df['SVM_Prediction'] = svm_model.predict(X)

# Display the first few rows of the modified DataFrame
print(df.head())

df.to_csv('data.csv', index=False)

comparison = pd.crosstab(df['Binary_Decision'], df['SVM_Prediction'], rownames=['Binary Decision'], colnames=['SVM Prediction'], margins=True)

comparison

import numpy as np
import pandas as pd
from skfuzzy import control as ctrl
import skfuzzy as fuzz
from sklearn.svm import SVC
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

# Assume 'df' already contains 'Fuzzy_Score' and 'Binary_Decision' from previous steps
np.random.seed(42)  # For reproducibility

# Simulate some data for demonstration (replace this with your actual data)
data = {
    'Proposal_ID': range(1, 101),
    'ROI': np.random.rand(100),
    'Risk': np.random.rand(100),
    'Alignment': np.random.rand(100),
    'Innovation': np.random.rand(100),
    'Past_Performance': np.random.rand(100),
    'Binary_Decision': np.random.choice([0, 1], 100),  # Assuming binary decision has been converted to 0 and 1
    'Fuzzy_Score': np.random.rand(100)  # Assuming fuzzy scores are already computed
}
df = pd.DataFrame(data)

# Split data for SVM classification
X = df[['ROI', 'Risk', 'Alignment', 'Innovation', 'Past_Performance']]
y = df['Binary_Decision']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# SVM classifier to predict based on initial features
svm_classifier = SVC(kernel='linear', probability=True)
svm_classifier.fit(X_train, y_train)
y_pred = svm_classifier.predict(X_test)
print(f"SVM Model accuracy: {accuracy_score(y_test, y_pred):.2f}")

# Assume the fuzzy scores are more reflective of the nuanced evaluations
# Prioritize proposals with high fuzzy scores for strategic analysis
threshold = 0.5  # Threshold for considering high fuzzy scores
df_high_potential = df[df['Fuzzy_Score'] > threshold]

# Define strategic weights and preference functions
weights = {
    'ROI': 0.3,
    'Risk': -0.2,
    'Alignment': 0.1,
    'Innovation': 0.25,
    'Past_Performance': 0.3
}

preference_functions = {
    'ROI': lambda x: np.log(1 + x),
    'Risk': lambda x: -np.sqrt(x),
    'Alignment': lambda x: 2 * x,
    'Innovation': lambda x: (x / 10) ** 2,
    'Past_Performance': lambda x: x,
}

# Calculate utility scores for high-potential proposals
df_high_potential['Utility_Score'] = df_high_potential.apply(
    lambda row: sum(
        weights[feature] * preference_functions[feature](row[feature]) for feature in weights
    ), axis=1
)

# Now, you can prioritize proposals further based on Utility Scores
# For demonstration, let's see the top 10 proposals by Utility Score
top_proposals = df_high_potential.sort_values(by='Utility_Score', ascending=False).head(10)
print(top_proposals[['Proposal_ID', 'Fuzzy_Score', 'Utility_Score']])

# Note: Remember to replace simulated data and assumptions with actual data and analysis results.

